# Paraphrasing-filters
This repository is part of my master's thesis.

# Pipeline for paraphrase filtering
In the repository notebook, a pipeline is developed that is capable of generating paraphrases, and applying semantic and lexical filters to them. In this way, it is intended to obtain the best candidates generated

To carry out the paraphrasing I use a transformer model with T5-Large architecture. The model is available in the Hugging Face hub under the name "ramsrigouthamg/t5-large-paraphraser-diverse-high-quality"

The semantic filter that is applied to the paraphrases is through an entailment recognition transformer model. This model follows a ROBERTa architecture. The model is private and its access is restricted in the notebook(the url of requests to the server with the model is censored).

To obtain the most promising candidates based on the paraphrases with greater lexical variety, the pipeline uses the ROUGE-1 metric by default, however the pipeline allows the use of other metrics such as BLEU score or Jaccard similarity.

# Generation of queries for misinformation tracking
The purpose of this pipeline is to generate lexically enriched queries, in order to track hoaxes on Twitter. That is why after the development of the pipeline, a set of queries are generated in the notebook through the use of a private model (query_builder_v3_1) that can extract the keywords and normalize the queries.

The final queries created were generated by concatenating the best candidates from the paraphrasing.
In the "cancer_en_queries.xlsx" file of the "Final queries for hoax tracking" folder you can find the lexically enriched final queries generated throughout the notebook.

